{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import re  # regular expressions for getting lat lon grid\n",
    "import pathlib\n",
    "import warnings\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import rasterio as rio # for extracting subsets\n",
    "from rasterio.plot import plotting_extent #for plotting\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import earthpy.mask as em\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.patches as mpatches\n",
    "import fnmatch  #for finding other file when city+rural isn't all in the main one (need 2 images to span full area)\n",
    "\n",
    "#for the reprojecting\n",
    "import pyproj\n",
    "from pyproj import CRS\n",
    "from pyproj import Transformer\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from pyhdf.SD import SD, SDC\n",
    "import datetime as dt\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "import geopandas as gpd\n",
    "\n",
    "#for finding the mode\n",
    "from collections import Counter\n",
    "\n",
    "#load in csv of city lons and lats and city details\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT', 'MEAN_SUHI'))\n",
    "\n",
    "CITY_COUNTRY_lat_lon = pd.read_excel('CITY_COUNTRY_lat_lon_mean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vegetation indices\n",
    "\n",
    "#function to extract the subdatasets of interest and return a dataframe \n",
    "#NDVI and EVI are vegetation indices\n",
    "#pixel reliability and VI quality are the quality checks\n",
    "\n",
    "def vi_dataframe_create(SATELLITE_NDVI, vi_file_name):#, city_top):\n",
    "    data_path = os.path.join(vi_file_name)\n",
    "    with rio.open(data_path) as dataset:\n",
    "    # Loop through each subdataset in HDF4 file\n",
    "        for name in dataset.subdatasets:\n",
    "        \n",
    "        # Use regular expression to identify if subdataset has NDVI in the name\n",
    "            if re.search(\"1 km monthly NDVI\", name):\n",
    "        \n",
    "                # Open the band subdataset\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                \n",
    "                    # Read band data as a 2 dim arr and append to list\n",
    "                    NDVI = subdataset.read(1)\n",
    "                \n",
    "            # Use regular expression to identify if subdataset has EVI in the name\n",
    "            if re.search(\"1 km monthly EVI\", name):\n",
    "        \n",
    "                # Open the band subdataset\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                \n",
    "                    # Read band data as a 2 dim arr and append to list\n",
    "                    EVI = subdataset.read(1)\n",
    "                \n",
    "       \n",
    "            # Use regular expression to identify if subdataset has reliability in the name (for pixel reliability)\n",
    "            if re.search(\"1 km monthly pixel reliability\", name):\n",
    "        \n",
    "                # Open the band subdataset\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                \n",
    "                    # Read band data as a 2 dim arr and append to list\n",
    "                    pixel_reliability = subdataset.read(1)\n",
    "                \n",
    "                \n",
    "              # Use regular expression to identify if subdataset has quality in the name (for VI Quality)\n",
    "            if re.search(\"1 km monthly VI Quality\", name):\n",
    "        \n",
    "                # Open the band subdataset\n",
    "                with rio.open(name) as subdataset:\n",
    "                    modis_meta = subdataset.profile\n",
    "                \n",
    "                    # Read band data as a 2 dim arr and append to list\n",
    "                    VI_quality = subdataset.read(1)       \n",
    "                \n",
    "                \n",
    "    #Create the coordinate grid\n",
    "    # Identify the data field- use the NDVI field but grid is same for all data\n",
    "    DATAFIELD_NAME = '1 km monthly EVI'\n",
    "\n",
    "    if SATELLITE_NDVI == 'MOD13A3':\n",
    "        GRID_NAME = 'MOD_Grid_monthly_1km_VI'\n",
    "    else:\n",
    "        GRID_NAME = 'MYD_Grid_monthly_1km_VI'\n",
    "        \n",
    "    hdf = SD(vi_file_name, SDC.READ)\n",
    "\n",
    "    # Read dataset.\n",
    "    data2D = hdf.select(DATAFIELD_NAME)\n",
    "    data = data2D[:,:].astype(np.float64)\n",
    "\n",
    "    # Read global attribute.\n",
    "    fattrs = hdf.attributes(full=1)\n",
    "    ga = fattrs[\"StructMetadata.0\"]\n",
    "    gridmeta = ga[0]\n",
    "\n",
    "    # Construct the grid.  Required information in global attribute called 'StructMetadata.0'\n",
    "\n",
    "    ul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n",
    "                                  (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n",
    "                                  ,\n",
    "                                  (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n",
    "                                  \\)''', re.VERBOSE)\n",
    "    match = ul_regex.search(gridmeta)\n",
    "    x0 = float(match.group('upper_left_x')) \n",
    "    y0 = float(match.group('upper_left_y')) \n",
    "\n",
    "    lr_regex = re.compile(r'''LowerRightMtrs=\\(\n",
    "                                  (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n",
    "                                  ,\n",
    "                                  (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n",
    "                                  \\)''', re.VERBOSE)\n",
    "    match = lr_regex.search(gridmeta)\n",
    "    x1 = float(match.group('lower_right_x')) \n",
    "    y1 = float(match.group('lower_right_y')) \n",
    "    ny, nx = data.shape\n",
    "    xinc = (x1 - x0) / nx\n",
    "    yinc = (y1 - y0) / ny\n",
    "\n",
    "    x = np.linspace(x0, x0 + xinc*nx, nx)\n",
    "    y = np.linspace(y0, y0 + yinc*ny, ny)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "    # convert the grid back to lat/lons.\n",
    "    transformer = Transformer.from_crs(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\", \"EPSG:4326\")\n",
    "    lat, lon = transformer.transform(xv, yv)\n",
    "\n",
    "    #Apply scale factors\n",
    "    scale_factor_NDVI = 0.0001\n",
    "    scale_factor_EVI = 0.0001\n",
    "\n",
    "    NDVI = NDVI*scale_factor_NDVI\n",
    "    EVI = EVI*scale_factor_EVI\n",
    "\n",
    "    #Create the lists to be combined to create a dataframe\n",
    "    NDVI_list = NDVI.flatten()\n",
    "    EVI_list = EVI.flatten()\n",
    "    pixel_reliability_list = pixel_reliability.flatten()\n",
    "    VI_quality_list = VI_quality.flatten()\n",
    "    Lon_list = lon.flatten()\n",
    "    Lat_list = lat.flatten()\n",
    "\n",
    "    #Create the dataframe\n",
    "\n",
    "    df = pd.DataFrame(list(zip(NDVI_list, EVI_list, pixel_reliability_list, VI_quality_list, Lon_list, Lat_list)), \n",
    "               columns =['NDVI', 'EVI','pixel_reliability', 'VI_quality','Longitude', 'Latitude']) \n",
    "\n",
    "    #Create dataframe of the required area\n",
    "    df_subset = df[(df.Latitude > min_lat) & (df.Latitude < max_lat) & (df.Longitude > min_lon) & (df.Longitude < max_lon)]\n",
    "    df_subset = df_subset.sort_values(by=['Latitude', 'Longitude']).reset_index(drop = True)\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of the urban mean evi and the rural mean evi\n",
    "#runtime start:11.39\n",
    "for m in range(len(CITY_COUNTRY_lat_lon)):\n",
    "\n",
    "    CITY_COUNTRY = CITY_COUNTRY_lat_lon.CITY_COUNTRY[m]\n",
    "    #Area to look at \n",
    "    min_lat = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['min_lat'].values[0]\n",
    "    max_lat = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['max_lat'].values[0]\n",
    "    min_lon = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['min_lon'].values[0]\n",
    "    max_lon = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['max_lon'].values[0]\n",
    "    Grid_Ref = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['Grid_Ref'].values[0]\n",
    "    \n",
    "    #load in the data with the list of the city vi files\n",
    "    #get lists of all the VI files and their months/ years\n",
    "    #TERRA\n",
    "    SATELLITE_NDVI = 'MOD13A3'\n",
    "    os.chdir(os.path.join('E:\\\\','City_Data','MODIS_NDVI', CITY_COUNTRY))\n",
    "    pickle_name = 'terra_IV_QC_check_{}.pkl'.format(CITY_COUNTRY)\n",
    "    with open(pickle_name, 'rb') as f:\n",
    "             vi_look_up_terra = pickle.load(f)\n",
    "            \n",
    "    vi_look_up_terra = vi_look_up_terra[vi_look_up_terra['Year'] != '2021'] #remove 2021 from the dataframe (not using)\n",
    "    vi_look_up_terra = vi_look_up_terra[vi_look_up_terra['Year'] != '2022'] #remove 2022 from the dataframe (not using)\n",
    "    \n",
    "    #AQUA\n",
    "    SATELLITE_NDVI = 'MYD13A3'\n",
    "    os.chdir(os.path.join('E:\\\\','City_Data','MODIS_NDVI', CITY_COUNTRY))\n",
    "    pickle_name = 'aqua_IV_QC_check_{}.pkl'.format(CITY_COUNTRY)\n",
    "    with open(pickle_name, 'rb') as f:\n",
    "             vi_look_up_aqua = pickle.load(f)\n",
    "    \n",
    "    vi_look_up_aqua = vi_look_up_aqua[vi_look_up_aqua['Year'] != '2021'] #remove 2021 from the dataframe (not using)\n",
    "    vi_look_up_aqua = vi_look_up_aqua[vi_look_up_aqua['Year'] != '2022'] #remove 2022 from the dataframe (not using)\n",
    "    \n",
    "    #Load in LULC data, these bases were created in JASMIN\n",
    "    os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT'))\n",
    "    with open('UHI_Project_Pickle_Files\\LULC_Pickles\\Crop_wbuffer_LULC\\LULC_{}.pkl'.format(CITY_COUNTRY), 'rb') as f:\n",
    "         LULC_df = pickle.load(f)\n",
    "    #make sure LULC sorted by latitude and longitude\n",
    "    LULC_df = LULC_df.sort_values(by=['Latitude', 'Longitude']).reset_index(drop = True)   \n",
    "\n",
    "    #create the df to be filled with the mean values\n",
    "    vi_means_df = vi_look_up_aqua.copy()\n",
    "    vi_means_df = vi_means_df.rename(columns={\"Filename\": \"Aqua_Filename\"})\n",
    "    vi_means_df['Terra_Filename'] = np.nan\n",
    "    vi_means_df['rur_mean_evi'] = np.nan\n",
    "    vi_means_df['urb_mean_evi'] = np.nan\n",
    "    vi_means_df['pixel_reliability_percent'] = np.nan        \n",
    "        \n",
    "    for n in range(len(vi_means_df)):     \n",
    "        #add the evi to the base\n",
    "        #create the aqua and terra dataframes\n",
    "        aqua_vi_file_name = vi_look_up_aqua.Filename[n]\n",
    "        aqua_mon =  vi_look_up_aqua.Month[n]\n",
    "        aqua_year = vi_look_up_aqua.Year[n]\n",
    "        SATELLITE_NDVI = 'MYD13A3'\n",
    "        os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref, SATELLITE_NDVI))\n",
    "        aqua_vi_df = vi_dataframe_create('MYD13A3', aqua_vi_file_name)\n",
    "        if CITY_COUNTRY in([\"BULAWAYO_ZIMBABWE\",'RIO_BRANCO_BRAZIL','SANHE_CHINA','DAYTON_USA']):\n",
    "            if CITY_COUNTRY == \"BULAWAYO_ZIMBABWE\":\n",
    "                Grid_Ref_top = 'h20v10'\n",
    "            elif CITY_COUNTRY == 'RIO_BRANCO_BRAZIL':\n",
    "                Grid_Ref_top = 'h11v10'  \n",
    "            elif CITY_COUNTRY == 'SANHE_CHINA':\n",
    "                Grid_Ref_top = 'h26v04'\n",
    "            elif CITY_COUNTRY == 'DAYTON_USA':\n",
    "                Grid_Ref_top = 'h11v04'\n",
    "            #add in other files for cities where the rural extent goes outside of the grid box\n",
    "            #Set path to chosen satellite\n",
    "            os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref_top, SATELLITE_NDVI))\n",
    "    \n",
    "            #extract the julian date of the main filename\n",
    "            yeardoy = aqua_vi_file_name.split('.')[1][1:] \n",
    "\n",
    "            #find the filename which contains this in the top of city files\n",
    "            for file in os.listdir('.'):\n",
    "                if fnmatch.fnmatch(file, '*{}*'.format(yeardoy)):\n",
    "                    top_file_name = file    \n",
    "        \n",
    "            top_file_df = vi_dataframe_create('MYD13A3',top_file_name)\n",
    "\n",
    "            aqua_vi_df = aqua_vi_df.append(top_file_df).reset_index(drop = True)\n",
    "            aqua_vi_df = aqua_vi_df.sort_values(by=['Latitude', 'Longitude']).reset_index(drop = True)\n",
    "            os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref, SATELLITE_NDVI))\n",
    "\n",
    "        try:\n",
    "            vi_look_up_terra[(vi_look_up_terra.Month == aqua_mon) & (vi_look_up_terra.Year == aqua_year)].Filename.values[0]\n",
    "        except IndexError:\n",
    "            terra_vi_df = aqua_vi_df.copy()\n",
    "        else:\n",
    "            terra_vi_file_name = vi_look_up_terra[(vi_look_up_terra.Month == aqua_mon) & (vi_look_up_terra.Year == aqua_year)].Filename.values[0]\n",
    "            SATELLITE_NDVI = 'MOD13A3'\n",
    "            os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref, SATELLITE_NDVI))\n",
    "            terra_vi_df = vi_dataframe_create('MOD13A3', terra_vi_file_name)\n",
    "            if CITY_COUNTRY in([\"BULAWAYO_ZIMBABWE\",'RIO_BRANCO_BRAZIL','SANHE_CHINA','DAYTON_USA']):\n",
    "                if CITY_COUNTRY == \"BULAWAYO_ZIMBABWE\":\n",
    "                    Grid_Ref_top = 'h20v10'\n",
    "                elif CITY_COUNTRY == 'RIO_BRANCO_BRAZIL':\n",
    "                    Grid_Ref_top = 'h11v10'  \n",
    "                elif CITY_COUNTRY == 'SANHE_CHINA':\n",
    "                    Grid_Ref_top = 'h26v04'\n",
    "                elif CITY_COUNTRY == 'DAYTON_USA':\n",
    "                    Grid_Ref_top = 'h11v04'\n",
    "                #add in other files for cities where the rural extent goes outside of the grid box\n",
    "                #Set path to chosen satellite\n",
    "                os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref_top, SATELLITE_NDVI))\n",
    "    \n",
    "                #extract the julian date of the main filename\n",
    "                yeardoy = terra_vi_file_name.split('.')[1][1:] \n",
    "\n",
    "                #find the filename which contains this in the top of city files\n",
    "                for file in os.listdir('.'):\n",
    "                    if fnmatch.fnmatch(file, '*{}*'.format(yeardoy)):\n",
    "                        top_file_name = file    \n",
    "        \n",
    "                top_file_df = vi_dataframe_create('MOD13A3',top_file_name)\n",
    "\n",
    "                terra_vi_df = terra_vi_df.append(top_file_df).reset_index(drop = True)\n",
    "                terra_vi_df = terra_vi_df.sort_values(by=['Latitude', 'Longitude']).reset_index(drop = True)\n",
    "                os.chdir(os.path.join('E:\\\\','Grid_Refs', Grid_Ref, SATELLITE_NDVI))\n",
    "\n",
    "        #create a df containing final evi values (if aqua not reliable, use terra)\n",
    "        LULC_df2 = LULC_df.copy()\n",
    "        LULC_df2['aqua_evi'] = aqua_vi_df.EVI.values\n",
    "        LULC_df2['aqua_pixel_reliability'] = aqua_vi_df.pixel_reliability.values\n",
    "        LULC_df2['terra_evi'] = terra_vi_df.EVI.values\n",
    "        LULC_df2['terra_pixel_reliability'] = terra_vi_df.pixel_reliability.values\n",
    "        LULC_df2['evi_final'] = aqua_vi_df.EVI.values\n",
    "        LULC_df2.loc[((LULC_df2['aqua_pixel_reliability'] == 1) & (LULC_df2['terra_pixel_reliability'] == 0)\n",
    "                 ), 'evi_final'] = LULC_df2['terra_evi']\n",
    "        LULC_df2['pixel_reliablity_final'] = 0\n",
    "        LULC_df2.loc[((LULC_df2['aqua_pixel_reliability'] == 1) & (LULC_df2['terra_pixel_reliability'] == 1)\n",
    "                 ), 'pixel_reliablity_final'] = 1\n",
    "\n",
    "        #calculate the average rur/ urb evi and pixel reliability percent\n",
    "        rur_mean_evi = LULC_df2[(LULC_df2['pixel_reliablity_final'] == 0)&(LULC_df2['is_urban_overall_{}'.format(aqua_year\n",
    "                                                                                        )] == 0)].evi_final.mean()\n",
    "        urb_mean_evi = LULC_df2[(LULC_df2['pixel_reliablity_final'] == 0)&(LULC_df2['is_urban_overall_{}'.format(aqua_year\n",
    "                                                                                        )] == 1 )].evi_final.mean()\n",
    "        pixel_reliability_percent = 100* len(LULC_df2[(LULC_df2['pixel_reliablity_final'] == 0)])/ len(LULC_df2)\n",
    "\n",
    "        #add to the overall dataframe with the list of files and the means\n",
    "        vi_means_df.loc[n,'Terra_Filename'] = terra_vi_file_name\n",
    "        vi_means_df.loc[n,'rur_mean_evi'] = rur_mean_evi\n",
    "        vi_means_df.loc[n,'urb_mean_evi'] = urb_mean_evi\n",
    "        vi_means_df.loc[n,'pixel_reliability_percent'] = pixel_reliability_percent\n",
    "\n",
    "    #save the df\n",
    "    os.chdir(os.path.join('E:\\\\','City_Data','MODIS_NDVI', CITY_COUNTRY))\n",
    "    pickle_name = 'vi_means_df_{}.pkl'.format(CITY_COUNTRY)\n",
    "    with open(pickle_name, 'wb') as f:\n",
    "        pickle.dump(vi_means_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
